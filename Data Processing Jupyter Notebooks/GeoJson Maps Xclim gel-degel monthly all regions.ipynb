{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import processing_netcdf as pcdf\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import shapely.geometry \n",
    "import numpy as np\n",
    "from shapely import geometry as gmty\n",
    "from geofeather import to_geofeather, from_geofeather\n",
    "import glob\n",
    "import os\n",
    "import pyarrow\n",
    "from xclim import ensembles as ens\n",
    "from xclim import subset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"dlyfrzthw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/ACCESS1-3_rcp45_dlyfrzthw_monthly.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/BNU-ESM_rcp45_dlyfrzthw_monthly.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/CanESM2_rcp45_dlyfrzthw_monthly.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/CMCC-CMS_rcp45_dlyfrzthw_monthly.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/GFDL-ESM2M_rcp45_dlyfrzthw_monthly.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/HadGEM2-CC_rcp45_dlyfrzthw_monthly.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/INM-CM4_rcp45_dlyfrzthw_monthly.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/IPSL-CM5A-LR_rcp45_dlyfrzthw_monthly.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/IPSL-CM5B-LR_rcp45_dlyfrzthw_monthly.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/MPI-ESM-LR_rcp45_dlyfrzthw_monthly.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/NorESM1-M_rcp45_dlyfrzthw_monthly.nc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Variable \n",
    "variable85=\"rcp85_\"+var+\"_monthly\"\n",
    "variable45=\"rcp45_\"+var+\"_monthly\"\n",
    "#variable=\"rcp[48]5_tg_mean_annual\"\n",
    "\n",
    "files85 = glob.glob(folder+\"*\"+variable85+\".nc\")\n",
    "files45 = glob.glob(folder+\"*\"+variable45+\".nc\")\n",
    "#ex: ACCESS1-3_rcp45_tn_mean_annual.nc\n",
    "files85\n",
    "files45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlist = [\"january\", \"february\", \"march\", \"april\", \"may\", \"june\", \"july\", \"august\", \"september\", \n",
    "             \"october\", \"november\", \"december\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR RCP 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting arrays by periods of time with Xclim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (lat: 320, lon: 416, realization: 11, time: 120)\n",
      "Coordinates:\n",
      "  * lat          (lat) float32 66.62331 66.53998 66.45665 ... 40.12437 40.04104\n",
      "  * time         (time) datetime64[ns] 1981-01-01 1982-01-01 ... 2100-01-01\n",
      "  * lon          (lon) float32 -89.04521 -88.96188 ... -54.54659 -54.46326\n",
      "  * realization  (realization) int64 0 1 2 3 4 5 6 7 8 9 10\n",
      "Data variables:\n",
      "    dlyfrzthw    (realization, time, lat, lon) float64 dask.array<chunksize=(1, 1, 320, 416), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:     CF-1.5\n",
      "    title:           ACCESS1-3 model output prepared for CMIP5 historical\n",
      "    history:         CMIP5 compliant file produced from raw ACCESS model outp...\n",
      "    institution:     CSIRO (Commonwealth Scientific and Industrial Research O...\n",
      "    source:          ACCESS1-3 2011. Atmosphere: AGCM v1.0 (N96 grid-point, 1...\n",
      "    redistribution:  Redistribution prohibited. For internal use only.\n",
      "1\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (lat: 320, lon: 416, realization: 11, time: 120)\n",
      "Coordinates:\n",
      "  * lat          (lat) float32 66.62331 66.53998 66.45665 ... 40.12437 40.04104\n",
      "  * time         (time) datetime64[ns] 1981-02-01 1982-02-01 ... 2100-02-01\n",
      "  * lon          (lon) float32 -89.04521 -88.96188 ... -54.54659 -54.46326\n",
      "  * realization  (realization) int64 0 1 2 3 4 5 6 7 8 9 10\n",
      "Data variables:\n",
      "    dlyfrzthw    (realization, time, lat, lon) float64 dask.array<chunksize=(1, 1, 320, 416), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:     CF-1.5\n",
      "    title:           ACCESS1-3 model output prepared for CMIP5 historical\n",
      "    history:         CMIP5 compliant file produced from raw ACCESS model outp...\n",
      "    institution:     CSIRO (Commonwealth Scientific and Industrial Research O...\n",
      "    source:          ACCESS1-3 2011. Atmosphere: AGCM v1.0 (N96 grid-point, 1...\n",
      "    redistribution:  Redistribution prohibited. For internal use only.\n",
      "2\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (lat: 320, lon: 416, realization: 11, time: 120)\n",
      "Coordinates:\n",
      "  * lat          (lat) float32 66.62331 66.53998 66.45665 ... 40.12437 40.04104\n",
      "  * time         (time) datetime64[ns] 1981-03-01 1982-03-01 ... 2100-03-01\n",
      "  * lon          (lon) float32 -89.04521 -88.96188 ... -54.54659 -54.46326\n",
      "  * realization  (realization) int64 0 1 2 3 4 5 6 7 8 9 10\n",
      "Data variables:\n",
      "    dlyfrzthw    (realization, time, lat, lon) float64 dask.array<chunksize=(1, 1, 320, 416), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:     CF-1.5\n",
      "    title:           ACCESS1-3 model output prepared for CMIP5 historical\n",
      "    history:         CMIP5 compliant file produced from raw ACCESS model outp...\n",
      "    institution:     CSIRO (Commonwealth Scientific and Industrial Research O...\n",
      "    source:          ACCESS1-3 2011. Atmosphere: AGCM v1.0 (N96 grid-point, 1...\n",
      "    redistribution:  Redistribution prohibited. For internal use only.\n",
      "3\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (lat: 320, lon: 416, realization: 11, time: 120)\n",
      "Coordinates:\n",
      "  * lat          (lat) float32 66.62331 66.53998 66.45665 ... 40.12437 40.04104\n",
      "  * time         (time) datetime64[ns] 1981-04-01 1982-04-01 ... 2100-04-01\n",
      "  * lon          (lon) float32 -89.04521 -88.96188 ... -54.54659 -54.46326\n",
      "  * realization  (realization) int64 0 1 2 3 4 5 6 7 8 9 10\n",
      "Data variables:\n",
      "    dlyfrzthw    (realization, time, lat, lon) float64 dask.array<chunksize=(1, 1, 320, 416), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:     CF-1.5\n",
      "    title:           ACCESS1-3 model output prepared for CMIP5 historical\n",
      "    history:         CMIP5 compliant file produced from raw ACCESS model outp...\n",
      "    institution:     CSIRO (Commonwealth Scientific and Industrial Research O...\n",
      "    source:          ACCESS1-3 2011. Atmosphere: AGCM v1.0 (N96 grid-point, 1...\n",
      "    redistribution:  Redistribution prohibited. For internal use only.\n",
      "4\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (lat: 320, lon: 416, realization: 11, time: 120)\n",
      "Coordinates:\n",
      "  * lat          (lat) float32 66.62331 66.53998 66.45665 ... 40.12437 40.04104\n",
      "  * time         (time) datetime64[ns] 1981-05-01 1982-05-01 ... 2100-05-01\n",
      "  * lon          (lon) float32 -89.04521 -88.96188 ... -54.54659 -54.46326\n",
      "  * realization  (realization) int64 0 1 2 3 4 5 6 7 8 9 10\n",
      "Data variables:\n",
      "    dlyfrzthw    (realization, time, lat, lon) float64 dask.array<chunksize=(1, 1, 320, 416), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:     CF-1.5\n",
      "    title:           ACCESS1-3 model output prepared for CMIP5 historical\n",
      "    history:         CMIP5 compliant file produced from raw ACCESS model outp...\n",
      "    institution:     CSIRO (Commonwealth Scientific and Industrial Research O...\n",
      "    source:          ACCESS1-3 2011. Atmosphere: AGCM v1.0 (N96 grid-point, 1...\n",
      "    redistribution:  Redistribution prohibited. For internal use only.\n",
      "5\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (lat: 320, lon: 416, realization: 11, time: 120)\n",
      "Coordinates:\n",
      "  * lat          (lat) float32 66.62331 66.53998 66.45665 ... 40.12437 40.04104\n",
      "  * time         (time) datetime64[ns] 1981-06-01 1982-06-01 ... 2100-06-01\n",
      "  * lon          (lon) float32 -89.04521 -88.96188 ... -54.54659 -54.46326\n",
      "  * realization  (realization) int64 0 1 2 3 4 5 6 7 8 9 10\n",
      "Data variables:\n",
      "    dlyfrzthw    (realization, time, lat, lon) float64 dask.array<chunksize=(1, 1, 320, 416), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:     CF-1.5\n",
      "    title:           ACCESS1-3 model output prepared for CMIP5 historical\n",
      "    history:         CMIP5 compliant file produced from raw ACCESS model outp...\n",
      "    institution:     CSIRO (Commonwealth Scientific and Industrial Research O...\n",
      "    source:          ACCESS1-3 2011. Atmosphere: AGCM v1.0 (N96 grid-point, 1...\n",
      "    redistribution:  Redistribution prohibited. For internal use only.\n",
      "6\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (lat: 320, lon: 416, realization: 11, time: 120)\n",
      "Coordinates:\n",
      "  * lat          (lat) float32 66.62331 66.53998 66.45665 ... 40.12437 40.04104\n",
      "  * time         (time) datetime64[ns] 1981-07-01 1982-07-01 ... 2100-07-01\n",
      "  * lon          (lon) float32 -89.04521 -88.96188 ... -54.54659 -54.46326\n",
      "  * realization  (realization) int64 0 1 2 3 4 5 6 7 8 9 10\n",
      "Data variables:\n",
      "    dlyfrzthw    (realization, time, lat, lon) float64 dask.array<chunksize=(1, 1, 320, 416), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:     CF-1.5\n",
      "    title:           ACCESS1-3 model output prepared for CMIP5 historical\n",
      "    history:         CMIP5 compliant file produced from raw ACCESS model outp...\n",
      "    institution:     CSIRO (Commonwealth Scientific and Industrial Research O...\n",
      "    source:          ACCESS1-3 2011. Atmosphere: AGCM v1.0 (N96 grid-point, 1...\n",
      "    redistribution:  Redistribution prohibited. For internal use only.\n",
      "7\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (lat: 320, lon: 416, realization: 11, time: 120)\n",
      "Coordinates:\n",
      "  * lat          (lat) float32 66.62331 66.53998 66.45665 ... 40.12437 40.04104\n",
      "  * time         (time) datetime64[ns] 1981-08-01 1982-08-01 ... 2100-08-01\n",
      "  * lon          (lon) float32 -89.04521 -88.96188 ... -54.54659 -54.46326\n",
      "  * realization  (realization) int64 0 1 2 3 4 5 6 7 8 9 10\n",
      "Data variables:\n",
      "    dlyfrzthw    (realization, time, lat, lon) float64 dask.array<chunksize=(1, 1, 320, 416), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:     CF-1.5\n",
      "    title:           ACCESS1-3 model output prepared for CMIP5 historical\n",
      "    history:         CMIP5 compliant file produced from raw ACCESS model outp...\n",
      "    institution:     CSIRO (Commonwealth Scientific and Industrial Research O...\n",
      "    source:          ACCESS1-3 2011. Atmosphere: AGCM v1.0 (N96 grid-point, 1...\n",
      "    redistribution:  Redistribution prohibited. For internal use only.\n",
      "8\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (lat: 320, lon: 416, realization: 11, time: 120)\n",
      "Coordinates:\n",
      "  * lat          (lat) float32 66.62331 66.53998 66.45665 ... 40.12437 40.04104\n",
      "  * time         (time) datetime64[ns] 1981-09-01 1982-09-01 ... 2100-09-01\n",
      "  * lon          (lon) float32 -89.04521 -88.96188 ... -54.54659 -54.46326\n",
      "  * realization  (realization) int64 0 1 2 3 4 5 6 7 8 9 10\n",
      "Data variables:\n",
      "    dlyfrzthw    (realization, time, lat, lon) float64 dask.array<chunksize=(1, 1, 320, 416), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:     CF-1.5\n",
      "    title:           ACCESS1-3 model output prepared for CMIP5 historical\n",
      "    history:         CMIP5 compliant file produced from raw ACCESS model outp...\n",
      "    institution:     CSIRO (Commonwealth Scientific and Industrial Research O...\n",
      "    source:          ACCESS1-3 2011. Atmosphere: AGCM v1.0 (N96 grid-point, 1...\n",
      "    redistribution:  Redistribution prohibited. For internal use only.\n",
      "9\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (lat: 320, lon: 416, realization: 11, time: 120)\n",
      "Coordinates:\n",
      "  * lat          (lat) float32 66.62331 66.53998 66.45665 ... 40.12437 40.04104\n",
      "  * time         (time) datetime64[ns] 1981-10-01 1982-10-01 ... 2100-10-01\n",
      "  * lon          (lon) float32 -89.04521 -88.96188 ... -54.54659 -54.46326\n",
      "  * realization  (realization) int64 0 1 2 3 4 5 6 7 8 9 10\n",
      "Data variables:\n",
      "    dlyfrzthw    (realization, time, lat, lon) float64 dask.array<chunksize=(1, 1, 320, 416), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:     CF-1.5\n",
      "    title:           ACCESS1-3 model output prepared for CMIP5 historical\n",
      "    history:         CMIP5 compliant file produced from raw ACCESS model outp...\n",
      "    institution:     CSIRO (Commonwealth Scientific and Industrial Research O...\n",
      "    source:          ACCESS1-3 2011. Atmosphere: AGCM v1.0 (N96 grid-point, 1...\n",
      "    redistribution:  Redistribution prohibited. For internal use only.\n",
      "10\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (lat: 320, lon: 416, realization: 11, time: 120)\n",
      "Coordinates:\n",
      "  * lat          (lat) float32 66.62331 66.53998 66.45665 ... 40.12437 40.04104\n",
      "  * time         (time) datetime64[ns] 1981-11-01 1982-11-01 ... 2100-11-01\n",
      "  * lon          (lon) float32 -89.04521 -88.96188 ... -54.54659 -54.46326\n",
      "  * realization  (realization) int64 0 1 2 3 4 5 6 7 8 9 10\n",
      "Data variables:\n",
      "    dlyfrzthw    (realization, time, lat, lon) float64 dask.array<chunksize=(1, 1, 320, 416), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:     CF-1.5\n",
      "    title:           ACCESS1-3 model output prepared for CMIP5 historical\n",
      "    history:         CMIP5 compliant file produced from raw ACCESS model outp...\n",
      "    institution:     CSIRO (Commonwealth Scientific and Industrial Research O...\n",
      "    source:          ACCESS1-3 2011. Atmosphere: AGCM v1.0 (N96 grid-point, 1...\n",
      "    redistribution:  Redistribution prohibited. For internal use only.\n",
      "11\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (lat: 320, lon: 416, realization: 11, time: 120)\n",
      "Coordinates:\n",
      "  * lat          (lat) float32 66.62331 66.53998 66.45665 ... 40.12437 40.04104\n",
      "  * time         (time) datetime64[ns] 1981-12-01 1982-12-01 ... 2100-12-01\n",
      "  * lon          (lon) float32 -89.04521 -88.96188 ... -54.54659 -54.46326\n",
      "  * realization  (realization) int64 0 1 2 3 4 5 6 7 8 9 10\n",
      "Data variables:\n",
      "    dlyfrzthw    (realization, time, lat, lon) float64 dask.array<chunksize=(1, 1, 320, 416), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:     CF-1.5\n",
      "    title:           ACCESS1-3 model output prepared for CMIP5 historical\n",
      "    history:         CMIP5 compliant file produced from raw ACCESS model outp...\n",
      "    institution:     CSIRO (Commonwealth Scientific and Industrial Research O...\n",
      "    source:          ACCESS1-3 2011. Atmosphere: AGCM v1.0 (N96 grid-point, 1...\n",
      "    redistribution:  Redistribution prohibited. For internal use only.\n"
     ]
    }
   ],
   "source": [
    "dsEns45= ens.create_ensemble(files45)\n",
    "dsEns45.time.dt.month[0:12]\n",
    "# Monthly example 30 y means\n",
    "listds = []\n",
    "i=0\n",
    "for s in dsEns45.time.dt.month[0:12]:\n",
    "    print (i)\n",
    "    tmp1 = dsEns45.sel(time=(dsEns45.time.dt.year>=1981))\n",
    "    tmp1 = tmp1.sel(time=(tmp1.time.dt.month==s))\n",
    "    print(tmp1)\n",
    "    i = i+1\n",
    "    listds.append(tmp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop to create all 12 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset number:  0 --------------\n",
      "Percentiles Obteined\n",
      "Converted to DF\n",
      "Split in 3 different time periods\n",
      "Transformed in Celsiuds and rounded\n",
      "pivoted\n",
      "DF pivoted\n",
      "january\n",
      "Columns renamed\n",
      "DF added to the list\n",
      "Dataset number:  1 --------------\n",
      "Percentiles Obteined\n",
      "Converted to DF\n",
      "Split in 3 different time periods\n",
      "Transformed in Celsiuds and rounded\n",
      "pivoted\n",
      "DF pivoted\n",
      "february\n",
      "Columns renamed\n",
      "DF added to the list\n",
      "Dataset number:  2 --------------\n",
      "Percentiles Obteined\n",
      "Converted to DF\n",
      "Split in 3 different time periods\n",
      "Transformed in Celsiuds and rounded\n",
      "pivoted\n",
      "DF pivoted\n",
      "march\n",
      "Columns renamed\n",
      "DF added to the list\n",
      "Dataset number:  3 --------------\n",
      "Percentiles Obteined\n",
      "Converted to DF\n",
      "Split in 3 different time periods\n",
      "Transformed in Celsiuds and rounded\n",
      "pivoted\n",
      "DF pivoted\n",
      "april\n",
      "Columns renamed\n",
      "DF added to the list\n",
      "Dataset number:  4 --------------\n",
      "Percentiles Obteined\n",
      "Converted to DF\n",
      "Split in 3 different time periods\n",
      "Transformed in Celsiuds and rounded\n",
      "pivoted\n",
      "DF pivoted\n",
      "may\n",
      "Columns renamed\n",
      "DF added to the list\n",
      "Dataset number:  5 --------------\n",
      "Percentiles Obteined\n",
      "Converted to DF\n",
      "Split in 3 different time periods\n",
      "Transformed in Celsiuds and rounded\n",
      "pivoted\n",
      "DF pivoted\n",
      "june\n",
      "Columns renamed\n",
      "DF added to the list\n",
      "Dataset number:  6 --------------\n",
      "Percentiles Obteined\n",
      "Converted to DF\n",
      "Split in 3 different time periods\n",
      "Transformed in Celsiuds and rounded\n",
      "pivoted\n",
      "DF pivoted\n",
      "july\n",
      "Columns renamed\n",
      "DF added to the list\n",
      "Dataset number:  7 --------------\n",
      "Percentiles Obteined\n",
      "Converted to DF\n",
      "Split in 3 different time periods\n",
      "Transformed in Celsiuds and rounded\n",
      "pivoted\n",
      "DF pivoted\n",
      "august\n",
      "Columns renamed\n",
      "DF added to the list\n",
      "Dataset number:  8 --------------\n",
      "Percentiles Obteined\n",
      "Converted to DF\n",
      "Split in 3 different time periods\n",
      "Transformed in Celsiuds and rounded\n",
      "pivoted\n",
      "DF pivoted\n",
      "september\n",
      "Columns renamed\n",
      "DF added to the list\n",
      "Dataset number:  9 --------------\n",
      "Percentiles Obteined\n",
      "Converted to DF\n",
      "Split in 3 different time periods\n",
      "Transformed in Celsiuds and rounded\n",
      "pivoted\n",
      "DF pivoted\n",
      "october\n",
      "Columns renamed\n",
      "DF added to the list\n",
      "Dataset number:  10 --------------\n",
      "Percentiles Obteined\n",
      "Converted to DF\n",
      "Split in 3 different time periods\n",
      "Transformed in Celsiuds and rounded\n",
      "pivoted\n",
      "DF pivoted\n",
      "november\n",
      "Columns renamed\n",
      "DF added to the list\n",
      "Dataset number:  11 --------------\n",
      "Percentiles Obteined\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "df45list = []\n",
    "for ds in listds:\n",
    "    print (\"Dataset number: \", i, \"--------------\")\n",
    "    perc45 = ens.ensemble_percentiles(ds)\n",
    "    print (\"Percentiles Obteined\")\n",
    "    df45 = perc45.to_dataframe()\n",
    "    df452 = df45.reset_index()\n",
    "    df45=0\n",
    "    df453 = df452.loc[df452[\"realization\"] == 0].dropna()\n",
    "    df452=0\n",
    "    print (\"Converted to DF\")\n",
    "    year_groups = {y:0 for y in range(1980,2011)}\n",
    "    year_groups.update({y:1 for y in range(2041,2071)})\n",
    "    year_groups.update({y:2 for y in range(2071,2101)})\n",
    "    dfp = df453.groupby([df453.time.dt.year.map(year_groups), \"lat\",\"lon\", \"realization\"]).mean()\n",
    "    dfp452 =  dfp.reset_index()\n",
    "    dfp=0\n",
    "    print (\"Split in 3 different time periods\")\n",
    "    df45C = dfp452.copy()\n",
    "    df45C[var+\"_p10\"] = round(df45C[var+\"_p10\"], 2)\n",
    "    df45C[var+\"_p50\"] = round(df45C[var+\"_p50\"], 2)\n",
    "    df45C[var+\"_p90\"] = round(df45C[var+\"_p90\"], 2)\n",
    "    print (\"Transformed in Celsiuds and rounded\")\n",
    "    Region1i45 = df45C.drop(columns=[\"realization\"])\n",
    "    df45C=0\n",
    "    print (\"pivoted\")\n",
    "    df45f = Region1i45.pivot_table(index=[\"lat\",\"lon\"], columns=\"time\")\n",
    "    Region1i45=0\n",
    "    print (\"DF pivoted\")\n",
    "    if i== 0: month = \"january\" \n",
    "    elif i == 1: month = \"february\"\n",
    "    elif i == 2: month = \"march\"\n",
    "    elif i == 3: month = \"april\"\n",
    "    elif i == 4: month = \"may\"\n",
    "    elif i == 5: month = \"june\"\n",
    "    elif i == 6: month = \"july\"\n",
    "    elif i == 7: month = \"august\"\n",
    "    elif i == 8: month = \"september\"\n",
    "    elif i == 9: month = \"october\"\n",
    "    elif i == 10: month = \"november\"\n",
    "    elif i == 11: month = \"december\"    \n",
    "    print (month)         \n",
    "    df45f.columns = [month + \"_\" + year + \"rcp45_p\"+p\n",
    "                     for p in [\"10\", \"50\", \"90\"]\n",
    "                     for year in [\"hist_\",\"t2050_\", \"t2080_\"]]\n",
    "    print(\"Columns renamed\")\n",
    "    df45list.append(df45f)\n",
    "    print (\"DF added to the list\")\n",
    "    i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df45list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_multiple_dfs(df_list, on):\n",
    "    df_result = df_list[0]\n",
    "    for df in df_list[1:]:\n",
    "        df_result = df_result.merge(df, on=on)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkey = [\"lat\", \"lon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfse45 = merge_multiple_dfs(df45list[0:12], on=mkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfse452 = dfse45.reset_index()\n",
    "dfse45=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfse452.to_feather(\"/home/mlopez/EXEC/Processed data to clip with regions/rcp45\"+var+\"_monthly.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfse452 = pd.read_feather(\"/home/mlopez/EXEC/Processed data to clip with regions/rcp45\"+var+\"_monthly.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfse453 = dfse452.drop(columns=[\"january_hist_rcp45_p10\",\"january_hist_rcp45_p50\", \"january_hist_rcp45_p90\", \n",
    "                               \"february_hist_rcp45_p10\", \"february_hist_rcp45_p50\", \"february_hist_rcp45_p90\", \n",
    "                               \"march_hist_rcp45_p10\",\"march_hist_rcp45_p50\", \"march_hist_rcp45_p90\", \n",
    "                               \"april_hist_rcp45_p10\",\"april_hist_rcp45_p50\", \"april_hist_rcp45_p90\",\n",
    "                              \"may_hist_rcp45_p10\",\"may_hist_rcp45_p50\", \"may_hist_rcp45_p90\", \n",
    "                               \"june_hist_rcp45_p10\", \"june_hist_rcp45_p50\", \"june_hist_rcp45_p90\", \n",
    "                               \"july_hist_rcp45_p10\",\"july_hist_rcp45_p50\", \"july_hist_rcp45_p90\", \n",
    "                               \"august_hist_rcp45_p10\",\"august_hist_rcp45_p50\", \"august_hist_rcp45_p90\",\n",
    "                              \"september_hist_rcp45_p10\",\"september_hist_rcp45_p50\", \"september_hist_rcp45_p90\", \n",
    "                               \"october_hist_rcp45_p10\", \"october_hist_rcp45_p50\", \"october_hist_rcp45_p90\", \n",
    "                               \"november_hist_rcp45_p10\",\"november_hist_rcp45_p50\", \"november_hist_rcp45_p90\", \n",
    "                               \"december_hist_rcp45_p10\",\"december_hist_rcp45_p50\", \"december_hist_rcp45_p90\"])\n",
    "dfse453\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lisdfmoh45 = []\n",
    "for month in monthlist: \n",
    "    dfmoh = dfse452[[\"lat\", \"lon\", month+\"_hist_rcp45_p50\"]]\n",
    "    print (month)\n",
    "    lisdfmoh45.append(dfmoh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR RCP 85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting arrays by periods of time with Xclim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsEns85= ens.create_ensemble(files85)\n",
    "dsEns85.time.dt.month[0:12]\n",
    "# Monthly example 30 y means\n",
    "listds85 = []\n",
    "i=0\n",
    "for s in dsEns85.time.dt.month[0:12]:\n",
    "    print (i)\n",
    "    tmp1 = dsEns85.sel(time=(dsEns85.time.dt.year>=1981))\n",
    "    tmp1 = tmp1.sel(time=(tmp1.time.dt.month==s))\n",
    "    print(tmp1)\n",
    "    i = i+1\n",
    "    listds85.append(tmp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop to create all 12 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "df85list = []\n",
    "for ds in listds85:\n",
    "    print (\"Dataset number: \", i)\n",
    "    perc85 = ens.ensemble_percentiles(ds)\n",
    "    print (\"Percentiles Obteined\")\n",
    "    df85 = perc85.to_dataframe()\n",
    "    df852 = df85.reset_index()\n",
    "    df85=0\n",
    "    df853 = df852.loc[df852[\"realization\"] == 0].dropna()\n",
    "    df852=0\n",
    "    print (\"Converted to DF\")\n",
    "    year_groups = {y:0 for y in range(1980,2011)}\n",
    "    year_groups.update({y:1 for y in range(2041,2071)})\n",
    "    year_groups.update({y:2 for y in range(2071,2101)})\n",
    "    dfp = df853.groupby([df853.time.dt.year.map(year_groups), \"lat\",\"lon\", \"realization\"]).mean()\n",
    "    dfp852 =  dfp.reset_index()\n",
    "    print (\"Split in 3 different time periods\")\n",
    "    df85C = dfp852.copy()\n",
    "    dfp852=0\n",
    "    df85C[var+\"_p10\"] = round(df85C[var+\"_p10\"], 2)\n",
    "    df85C[var+\"_p50\"] = round(df85C[var+\"_p50\"], 2)\n",
    "    df85C[var+\"_p90\"] = round(df85C[var+\"_p90\"], 2)\n",
    "    print (\"Transformed in Celsiuds and rounded\")\n",
    "    Region1i85 = df85C.drop(columns=[\"realization\"])\n",
    "    print (\"pivoted\")\n",
    "    df85f = Region1i85.pivot_table(index=[\"lat\",\"lon\"], columns=\"time\")\n",
    "    Region1i85=0\n",
    "    print (\"DF pivoted\")\n",
    "    if i== 0: month = \"january\" \n",
    "    elif i == 1: month = \"february\"\n",
    "    elif i == 2: month = \"march\"\n",
    "    elif i == 3: month = \"april\"\n",
    "    elif i == 4: month = \"may\"\n",
    "    elif i == 5: month = \"june\"\n",
    "    elif i == 6: month = \"july\"\n",
    "    elif i == 7: month = \"august\"\n",
    "    elif i == 8: month = \"september\"\n",
    "    elif i == 9: month = \"october\"\n",
    "    elif i == 10: month = \"november\"\n",
    "    elif i == 11: month = \"december\"    \n",
    "    print (month)\n",
    "    df85f.columns = [month + \"_\" + year + \"rcp85_p\"+p\n",
    "                     for p in [\"10\", \"50\", \"90\"]\n",
    "                     for year in [\"hist_\",\"t2050_\", \"t2080_\"]]\n",
    "    print(\"Columns renamed\")\n",
    "    df85list.append(df85f)\n",
    "    print (\"DF added to the list\")\n",
    "    i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df85list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfse85 = merge_multiple_dfs(df85list[0:12], on=mkey).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfse85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfse85.to_feather(\"/home/mlopez/EXEC/Processed data to clip with regions/rcp85\"+var+\"_monthly.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfse85 = pd.read_feather(\"/home/mlopez/EXEC/Processed data to clip with regions/rcp85\"+var+\"_monthly.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfse852 = dfse85.drop(columns=[\"january_hist_rcp85_p10\",\"january_hist_rcp85_p50\", \"january_hist_rcp85_p90\", \n",
    "                               \"february_hist_rcp85_p10\", \"february_hist_rcp85_p50\", \"february_hist_rcp85_p90\", \n",
    "                               \"march_hist_rcp85_p10\",\"march_hist_rcp85_p50\", \"march_hist_rcp85_p90\", \n",
    "                               \"april_hist_rcp85_p10\",\"april_hist_rcp85_p50\", \"april_hist_rcp85_p90\",\n",
    "                              \"may_hist_rcp85_p10\",\"may_hist_rcp85_p50\", \"may_hist_rcp85_p90\", \n",
    "                               \"june_hist_rcp85_p10\", \"june_hist_rcp85_p50\", \"june_hist_rcp85_p90\", \n",
    "                               \"july_hist_rcp85_p10\",\"july_hist_rcp85_p50\", \"july_hist_rcp85_p90\", \n",
    "                               \"august_hist_rcp85_p10\",\"august_hist_rcp85_p50\", \"august_hist_rcp85_p90\",\n",
    "                              \"september_hist_rcp85_p10\",\"september_hist_rcp85_p50\", \"september_hist_rcp85_p90\", \n",
    "                               \"october_hist_rcp85_p10\", \"october_hist_rcp85_p50\", \"october_hist_rcp85_p90\", \n",
    "                               \"november_hist_rcp85_p10\",\"november_hist_rcp85_p50\", \"november_hist_rcp85_p90\", \n",
    "                               \"december_hist_rcp85_p10\",\"december_hist_rcp85_p50\", \"december_hist_rcp85_p90\"])\n",
    "dfse852\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lisdfmoh85 = []\n",
    "for month in monthlist: \n",
    "    dfmoh = dfse85[[\"lat\", \"lon\", month+\"_hist_rcp85_p50\"]]\n",
    "    print (month)\n",
    "    lisdfmoh85.append(dfmoh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lisdfmoh85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge df45 and 85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting historic mean for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function\n",
    "def mean_month(month, dfse45, dfse85):\n",
    "    print(month)\n",
    "    dfw45 = dfse45[[\"lat\", \"lon\", month+\"_hist_rcp45_p50\"]]\n",
    "    dfw85 = dfse85[[\"lat\", \"lon\", month+\"_hist_rcp85_p50\"]]\n",
    "    dfsew = pd.merge(dfw45, dfw85, on=[\"lat\",\"lon\"])\n",
    "    dfw45=0\n",
    "    dfw85=0\n",
    "    dfsew[month+\"_hist_p50\"] = round((dfsew[month+\"_hist_rcp45_p50\"]+ dfsew[month+\"_hist_rcp85_p50\"])/2, 2)\n",
    "    dftgwh2 = dfsew.reset_index()\n",
    "    dfsew=0\n",
    "    dftgwh3 = dftgwh2[[\"lat\", \"lon\", month+\"_hist_p50\"]]\n",
    "    dftgwh2=0\n",
    "    return (dftgwh3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All months historic mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listdfmo = []\n",
    "i=0\n",
    "for month in monthlist:\n",
    "    print(month)\n",
    "    dfm = mean_month(month, lisdfmoh45[i], lisdfmoh85[i])\n",
    "    i = i+1\n",
    "    listdfmo.append(dfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge means with the 45 and 85 DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftgseall = dfse852.merge(dfse452, on=mkey)\n",
    "i=0\n",
    "for df in listdfmo:\n",
    "    dftgseall2 = dftgseall.merge(listdfmo[i], on=mkey)\n",
    "    i = i +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftgseall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmop50 = merge_multiple_dfs(listdfmo[0:12], on=mkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmop50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftgseall2 = dfse852.merge(dfse452, on=mkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dftgseall = dfse852.merge(dfse452, on=mkey).merge(dftfah, on=mkey).merge(dftsuh, on=mkey).merge(dftsph, on=mkey).merge(dftgwh, on=mkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftgseall2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftgseall3 = dftgseall2.merge(dfmop50, on=mkey)\n",
    "dftgseall2=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftgseall3.to_feather(\"/home/mlopez/EXEC/Processed data to clip with regions/\"+var+\"_monthly.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftgseall3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge complete DF with Polygons for each spatial scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary - regions: column name, short name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_dict = {\"DDE_STF_20K_REG_FOR_VUE_S\": (\"NM_REG_FOR\", \"RF\"), \n",
    "            \"DDE_STF_20K_UA_PER_VUE_S\": (\"PER_NO_UA\", \"UA\"), \n",
    "              \"DOM_BIO\": (\"NOM\", \"DB\"), \n",
    "              \"REG_ECO\": (\"NOM\", \"RE\"), \n",
    "              \"SDOM_BIO\": (\"NOM\", \"SDB\"), \n",
    "              \"Secteurs_Operations_Regionales\": (\"D_GENERAL\", \"SOR\"), \n",
    "              \"SREG_ECO\": (\"NOM\", \"SRE\"),  \n",
    "              \"territoire_guide\": (\"TER_GUIDE\", \"TG\") \n",
    "              }\n",
    "\n",
    "for region, (name, short) in short_dict.items():\n",
    "    print(region, name, short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = { 'BAS-SAINT-LAURENT':\"Bas-Saint-Laurent\", \n",
    "     'SAGUENAY -LAC-SAINT-JEAN': \"Saguenay -Lac-Saint-Jean\",\n",
    "     'CAPITALE-NATIONALE-CHAUDIÈRE-APPALACHES':\"Capitale-Nationale-Chaudiere-Appalaches\",\n",
    "     'MAURICIE-CENTRE-DU-QUÉBEC':'Mauricie-Centre-du-Quebec','OUTAOUAIS':'Outaouais', \n",
    "     'ABITIBI-TEMISCAMINGUE':'Abitibi-Temiscamingue', 'COTE-NORD':'Cote-Nord',\n",
    "     'NORD-DU-QUEBEC':'Nord-Du-Quebec', 'GASPESIE-ILES-DE-LA-MADELEINE':'Gaspesie-Iles-De-La-Madeleine', \n",
    "     'LANAUDIERE':'Lanaudiere','LAURENTIDES':\"Laurentides\", \n",
    "     \"ESTRIE-MONTÉRÉGIE-LAVAL-MONTRÉAL\":\"Estrie-Monteregie-Laval-Montreal\", \n",
    "     \"é\": \"e\", \"É\": \"E\", \"à\": \"a\", \"è\": \"e\", \"Î\": \"i\", \"È\": \"E\", \"ô\" : \"o\", \"Ç\":\"C\", \"ç\":\"c\",\n",
    "       } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region, (name, short) in short_dict.items():\n",
    "    print(region)\n",
    "    dfpolyshape = from_geofeather('/home/mlopez/EXEC/Grids-polygons-regions/Grid-'+region+'.feather')\n",
    "    dftp = pd.merge(dftgseall3, dfpolyshape, on=[\"lat\",\"lon\"])\n",
    "    dfpolyshape = 0\n",
    "    print (\"Merged with polygons\")\n",
    "    listTG = []\n",
    "    for tg in dftp[name].unique().tolist():\n",
    "        df2 = dftp[dftp[name] == tg]\n",
    "        print (tg)\n",
    "        if tg != None:\n",
    "            listTG.append(df2)\n",
    "        #print (listTG)\n",
    "    for df in listTG:\n",
    "        geometry = df[\"geometry\"]\n",
    "        crs = {'init': \"epsg:4326\"}\n",
    "        gdf = GeoDataFrame(df, crs=crs, geometry=geometry)\n",
    "        print (gdf[name].iloc[0])\n",
    "        #Substitute filename accents\n",
    "        gdf.to_file(replace_all(\"/home/mlopez/EXEC/GeoJsonMFFP/\"+gdf[name].iloc[0], d)+\"_\"+var+\"_monthly.json\", driver=\"GeoJSON\")\n",
    "    geometry = dftp[\"geometry\"]\n",
    "    crs = {'init': \"epsg:4326\"}\n",
    "    gdf = GeoDataFrame(dftp, crs=crs, geometry=geometry)\n",
    "    gdf.to_file(\"/home/mlopez/EXEC/GeoJsonMFFP/\"+short+\"_\"+var+\"_monthly.json\", driver=\"GeoJSON\")\n",
    "    dftp = 0\n",
    "    gdf = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
